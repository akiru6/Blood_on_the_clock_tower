# Base URL for the OpenAI instance (default is https://api.openai.com/v1)
# OpenAI: https://api.openai.com/v1
# Ollama (example): http://localhost:11434/v1
OPENROUTER_API_KEY=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
OpenRouter= https://openrouter.ai/api/v1
BASE_URL=https://api.groq.com/openai/v1

SerpAPI=a6f3c162630a52157f0b7a9349f94c725451c33437ffbc62dbae532baf6cc227
deepseek_api_key=sk-8c9ffb9af5b64b6f94c3a37bcc57ccf7
GOOGLE_API_KEY=AIzaSyC0quFb22Mf9e6B-QP5uVQqItW8xPrAF1k
# Get your Open AI API Key by following these instructions -
# https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key
# Even if using OpenRouter/Ollama, you still need to set this for the embedding model.
# Future versions of Archon will be more flexible with this.
OPENAI_API_KEY=

# For OpenAI: https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key
# For OpenRouter: https://openrouter.ai/keys
LLM_API_KEY=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
GROQ_API_KEY=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
# For the Supabase version (sample_supabase_agent.py), set your Supabase URL and Service Key.
# Get your SUPABASE_URL from the API section of your Supabase project settings -
# https://supabase.com/dashboard/project/<your project ID>/settings/api

SUPABASE_URL=https://qhvcnhltyydqgjatrcky.supabase.co

# Get your SUPABASE_SERVICE_KEY from the API section of your Supabase project settings -
# https://supabase.com/dashboard/project/<your project ID>/settings/api
# On this page it is called the service_role secret.
SUPABASE_SERVICE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InFodmNuaGx0eXlkcWdqYXRyY2t5Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTczOTY4MzQ3MSwiZXhwIjoyMDU1MjU5NDcxfQ.MmOjYgxWWXDZPfs3TQWGfu8uJJgiyGqwsxPMI8Nr2S4

COHERE_API_KEY=nBQjkpp0xNtcJlwhPqiwDEGVyrfKtM3CEzSL5wTU
# The LLM you want to use for the reasoner (o3-mini, R1, QwQ, etc.).
# Example: o3-mini
# Example: deepseek-r1:7b-8k
REASONER_MODEL=

# The LLM you want to use for the primary agent/coder.
# Example: gpt-4o-mini
# Example: qwen2.5:14b-instruct-8k
# Example: deepseek-r1-distill-llama-70b
PRIMARY_MODEL=openai/gpt-4o-mini
DEFAULT_MODEL = deepseek-r1-distill-llama-70b