# Feature: Modular Clarification Sub-Process for Ambiguous Inputs

**Status:** Planned / Future Enhancement
**Logged:** 2025-04-16
**Origin:** Discussion following implementation of direct GM interpretation for key-based action failures.

## 1. Goal

To improve the modularity, maintainability, and extensibility of handling ambiguous or incorrectly formatted inputs from AI agents, particularly for actions requiring a specific choice (like voting, killing, investigating).

Currently, the logic for handling parsing failures, attempting interpretation (GM direct interpretation), and potentially interactive clarification (future) resides partially within the main action nodes (`imp_action`, `voting_phase`, etc.) and the `handle_agent_decision_failure` utility function. This can lead to:

*   Increased complexity within the main game flow nodes.
*   Difficulty in reusing clarification logic across different action types.
*   Challenges in evolving the clarification strategy (e.g., from simple interpretation to multi-step LLM dialogue) without modifying multiple core components.

This feature proposes creating a dedicated, self-contained sub-process (likely implemented as a callable LangGraph subgraph/Runnable) specifically for resolving ambiguous inputs.

## 2. Proposed Solution: Clarification Subgraph

Instead of handling complex recovery logic directly within `handle_agent_decision_failure` or the main nodes, we will introduce a **Clarification Subgraph**.

*   **Trigger:** When a main action node receives an ambiguous/unparsable response from `get_decision` (e.g., status `parsing_failed`), instead of immediately declaring failure or having the GM utility handle everything, it will invoke this Clarification Subgraph.
*   **Implementation:** Likely using LangGraph's ability to compile a graph into a callable Runnable (`clarification_runnable = clarification_graph.compile()`). This provides excellent encapsulation.
*   **Internal Logic (Flexible):** The *internal* workings of the Clarification Subgraph can evolve:
    *   **Initial Version:** Could encapsulate the current "GM Direct Interpretation" logic (use regex/heuristics to extract intent from ambiguous output).
    *   **Future Version:** Could implement a multi-step interaction loop:
        1.  GM Agent node analyzes the failure and formulates a clarification question.
        2.  Player Agent node receives the question and attempts to provide a clearer response.
        3.  Evaluation node checks the new response.
        4.  Loop or conclude based on the evaluation.
*   **Encapsulation:** All state management related to the clarification attempt (e.g., retry counts) would be contained within the subgraph.

## 3. Inputs and Outputs

*   **Inputs to Subgraph:**
    *   `original_state_snapshot`: Relevant parts of the game state when the failure occurred.
    *   `failure_details`: The dictionary describing the initial failure (containing `raw_output`, `cleaned_output`, `intended_action`, `player_id`, etc.).
    *   `options`: The valid choices the player had (if applicable).
*   **Outputs from Subgraph:**
    *   `status`: `'recovered'` or `'failed'`.
    *   `recovered_data`: The successfully clarified/interpreted data (e.g., the valid key string) if `status` is `'recovered'`.
    *   `logs_added`: Any log entries generated during the clarification process.
    *   `(Potentially)` `updated_state_fields`: Any direct state modifications made during clarification (e.g., updating `pending_night_results` if investigation clarification fails).

## 4. Benefits

*   **Modularity:** Isolates clarification logic.
*   **Reusability:** The same subgraph can potentially handle clarification for votes, kills, investigations, etc.
*   **Maintainability:** Easier to update or fix clarification logic in one place.
*   **Extensibility:** Allows swapping clarification strategies (interpretation vs. interaction) without major refactoring of the main game flow.
*   **Cleaner Main Nodes:** Reduces the conditional logic needed within `imp_action`, `voting_phase`, etc.

## 5. Integration Points

The primary change would be within the main action nodes (`imp_action`, `investigator_action`, `voting_phase`, potentially `discussion_phase` if clarifying intents becomes necessary).

*   After calling `get_decision`, check the result.
*   If the result indicates a parsing failure suitable for clarification:
    *   Invoke the `clarification_runnable.invoke(...)` with necessary inputs.
    *   Process the dictionary returned by the runnable to determine the final outcome (use `recovered_data` or handle `failed` status).
*   The `handle_agent_decision_failure` utility might become simpler, focusing primarily on non-recoverable errors (`llm_call_failed`, `exception`) or acting as the initial check before delegating to the subgraph.

## 6. Next Steps & Priority

*   **Priority:** Medium. Implement after stabilizing the current version with the "GM Direct Interpretation" logic working reliably.
*   **Design:** Define the specific state, nodes, and edges for the `clarification_graph`.
*   **Implement:** Code the nodes and compile the runnable.
*   **Refactor:** Modify the main action nodes to call the clarification runnable instead of relying solely on the expanded `handle_agent_decision_failure`.
*   **Test:** Thoroughly test various ambiguous input scenarios.